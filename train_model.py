import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

# Importaciones modernas de TensorFlow
import tensorflow as tf
from keras import layers
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import MobileNetV2
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import warnings
warnings.filterwarnings('ignore')

class EntrenadorEnfermedadesOculares:
    def __init__(self):
        # Mapeo de clases en espa√±ol
        self.informacion_clases = {
            'Central Serous Chorioretinopathy [Color Fundus]': {
                'nombre': 'Corioretinopat√≠a Serosa Central',
                'descripcion': 'Acumulaci√≥n de l√≠quido bajo la retina que causa visi√≥n borrosa'
            },
            'Diabetic Retinopathy': {
                'nombre': 'Retinopat√≠a Diab√©tica',
                'descripcion': 'Da√±o a los vasos sangu√≠neos de la retina por diabetes'
            },
            'Disc Edema': {
                'nombre': 'Edema del Disco √ìptico',
                'descripcion': 'Hinchaz√≥n del disco √≥ptico por aumento de presi√≥n intracraneal'
            },
            'Glaucoma': {
                'nombre': 'Glaucoma',
                'descripcion': 'Da√±o al nervio √≥ptico, generalmente por presi√≥n ocular alta'
            },
            'Healthy': {
                'nombre': 'Ojo Sano',
                'descripcion': 'Retina sin patolog√≠as evidentes'
            },
            'Macular Scar': {
                'nombre': 'Cicatriz Macular',
                'descripcion': 'Tejido cicatricial en la m√°cula que afecta la visi√≥n central'
            },
            'Myopia': {
                'nombre': 'Miop√≠a',
                'descripcion': 'Error refractivo que causa dificultad para ver objetos lejanos'
            },
            'Pterygium': {
                'nombre': 'Pterigi√≥n',
                'descripcion': 'Crecimiento anormal de tejido sobre la c√≥rnea'
            },
            'Retinal Detachment': {
                'nombre': 'Desprendimiento de Retina',
                'descripcion': 'Separaci√≥n de la retina de la pared posterior del ojo'
            },
            'Retinitis Pigmentosa': {
                'nombre': 'Retinitis Pigmentosa',
                'descripcion': 'Degeneraci√≥n progresiva de la retina'
            }
        }
        
        # Configuraci√≥n del modelo
        self.alto_img = 224
        self.ancho_img = 224
        self.tama√±o_lote = 64
        self.division_validacion = 0.15
        
    def analizar_dataset(self, ruta_dataset):
        """Analiza el dataset antes del entrenamiento"""
        print("üìä Analizando dataset...")
        print("=" * 50)
        
        conteos_clases = {}
        total_imagenes = 0
        
        for nombre_clase in os.listdir(ruta_dataset):
            ruta_clase = os.path.join(ruta_dataset, nombre_clase)
            if os.path.isdir(ruta_clase):
                archivos_imagen = [f for f in os.listdir(ruta_clase) 
                             if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
                conteo = len(archivos_imagen)
                nombre_espa√±ol = self.informacion_clases.get(nombre_clase, {}).get('nombre', nombre_clase)
                conteos_clases[nombre_espa√±ol] = conteo
                total_imagenes += conteo
                print(f"‚úÖ {nombre_espa√±ol}: {conteo} im√°genes")
        
        print("=" * 50)
        print(f"üìà Total de im√°genes: {total_imagenes}")
        print(f"üìÅ N√∫mero de clases: {len(conteos_clases)}")
        print(f"üìä Promedio por clase: {total_imagenes/len(conteos_clases):.0f}")
        
        # Verificar balance
        conteos = list(conteos_clases.values())
        conteo_minimo, conteo_maximo = min(conteos), max(conteos)
        ratio_balance = conteo_minimo / conteo_maximo
        
        if ratio_balance < 0.5:
            print("‚ö†Ô∏è  Dataset desbalanceado - considera t√©cnicas de balanceo")
        else:
            print("‚úÖ Dataset relativamente balanceado")
        
        print("=" * 50)
        return conteos_clases, total_imagenes
    
    def preparar_datos(self, ruta_dataset):
        """Prepara los generadores de datos"""
        print("üîÑ Preparando generadores de datos...")
        
        # Data augmentation para entrenamiento
        generador_datos_entrenamiento = ImageDataGenerator(
            rescale=1./255,
            rotation_range=25,
            width_shift_range=0.15,
            height_shift_range=0.15,
            shear_range=0.1,
            zoom_range=0.15,
            horizontal_flip=True,
            brightness_range=[0.8, 1.2],
            fill_mode='nearest',
            validation_split=self.division_validacion
        )
        
        # Solo rescaling para validaci√≥n
        generador_datos_validacion = ImageDataGenerator(
            rescale=1./255,
            validation_split=self.division_validacion
        )
        
        # Generador de entrenamiento
        generador_entrenamiento = generador_datos_entrenamiento.flow_from_directory(
            ruta_dataset,
            target_size=(self.alto_img, self.ancho_img),
            batch_size=self.tama√±o_lote,
            class_mode='categorical',
            subset='training',
            shuffle=True
        )
        
        # Generador de validaci√≥n
        generador_validacion = generador_datos_validacion.flow_from_directory(
            ruta_dataset,
            target_size=(self.alto_img, self.ancho_img),
            batch_size=self.tama√±o_lote,
            class_mode='categorical',
            subset='validation',
            shuffle=False
        )
        
        print(f"‚úÖ Datos de entrenamiento: {generador_entrenamiento.samples} im√°genes")
        print(f"‚úÖ Datos de validaci√≥n: {generador_validacion.samples} im√°genes")
        
        return generador_entrenamiento, generador_validacion
    
    def crear_modelo(self, num_clases):
        """Crea el modelo con transfer learning"""
        print("üß† Creando modelo con transfer learning...")
        
        # Modelo base preentrenado
        modelo_base = MobileNetV2(
            weights='imagenet',
            include_top=False,
            input_shape=(self.alto_img, self.ancho_img, 3)
        )
        
        # Fine-tuning: descongelar las √∫ltimas capas
        modelo_base.trainable = True
        for capa in modelo_base.layers[:-20]:
            capa.trainable = False
        
        # Construir modelo completo
        modelo = tf.keras.Sequential([
            modelo_base,
            layers.GlobalAveragePooling2D(),
            layers.Dropout(0.4),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(128, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.2),
            layers.Dense(num_clases, activation='softmax')
        ])
        
        # Compilar modelo
        modelo.compile(
            optimizer=Adam(learning_rate=0.0001),
            loss='categorical_crossentropy',
            metrics=['accuracy', 'top_k_categorical_accuracy']
        )
        
        # Mostrar resumen
        print("üìã Resumen del modelo:")
        modelo.summary()
        
        return modelo
    
    def entrenar_modelo(self, ruta_dataset, epocas=20, ruta_guardado='eye_disease_model.h5'):
        """Entrena el modelo completo"""
        print("üöÄ Iniciando entrenamiento...")
        print("=" * 50)
        
        # Analizar dataset
        self.analizar_dataset(ruta_dataset)
        
        # Preparar datos
        gen_entrenamiento, gen_validacion = self.preparar_datos(ruta_dataset)
        num_clases = len(gen_entrenamiento.class_indices)
        
        # Crear modelo
        modelo = self.crear_modelo(num_clases)
        
        # Callbacks
        callbacks = [
            EarlyStopping(
                monitor='val_accuracy',
                patience=7,
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.2,
                patience=4,
                min_lr=0.00001,
                verbose=1
            ),
            ModelCheckpoint(
                ruta_guardado,
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            )
        ]
        
        # Entrenar
        print(f"üéØ Entrenando por {epocas} √©pocas...")
        historial = modelo.fit(
            gen_entrenamiento,
            epochs=epocas,
            validation_data=gen_validacion,
            callbacks=callbacks,
            verbose=1
        )
        
        # Guardar clases para la aplicaci√≥n principal
        indices_clases = gen_entrenamiento.class_indices
        np.save('class_indices.npy', indices_clases)
        
        print("=" * 50)
        print(f"‚úÖ Modelo guardado como: {ruta_guardado}")
        print(f"‚úÖ √çndices de clases guardados como: class_indices.npy")
        
        # Mostrar m√©tricas finales
        self.graficar_resultados_entrenamiento(historial)
        self.evaluar_modelo(modelo, gen_validacion)
        
        return modelo, historial
    
    def graficar_resultados_entrenamiento(self, historial):
        """Visualiza los resultados del entrenamiento"""
        print("üìà Generando gr√°ficos de entrenamiento...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Accuracy
        axes[0, 0].plot(historial.history['accuracy'], label='Entrenamiento', color='blue')
        axes[0, 0].plot(historial.history['val_accuracy'], label='Validaci√≥n', color='red')
        axes[0, 0].set_title('Precisi√≥n del Modelo')
        axes[0, 0].set_xlabel('√âpoca')
        axes[0, 0].set_ylabel('Precisi√≥n')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # Loss
        axes[0, 1].plot(historial.history['loss'], label='Entrenamiento', color='blue')
        axes[0, 1].plot(historial.history['val_loss'], label='Validaci√≥n', color='red')
        axes[0, 1].set_title('P√©rdida del Modelo')
        axes[0, 1].set_xlabel('√âpoca')
        axes[0, 1].set_ylabel('P√©rdida')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # Top-k accuracy
        axes[1, 0].plot(historial.history['top_k_categorical_accuracy'], label='Top-K Entrenamiento', color='green')
        axes[1, 0].plot(historial.history['val_top_k_categorical_accuracy'], label='Top-K Validaci√≥n', color='orange')
        axes[1, 0].set_title('Top-K Categorical Accuracy')
        axes[1, 0].set_xlabel('√âpoca')
        axes[1, 0].set_ylabel('Top-K Accuracy')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        # Learning rate (si est√° disponible)
        if 'lr' in historial.history:
            axes[1, 1].plot(historial.history['lr'], color='purple')
            axes[1, 1].set_title('Learning Rate')
            axes[1, 1].set_xlabel('√âpoca')
            axes[1, 1].set_ylabel('Learning Rate')
            axes[1, 1].set_yscale('log')
            axes[1, 1].grid(True)
        else:
            axes[1, 1].text(0.5, 0.5, 'Learning Rate\nno disponible', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
        
        plt.tight_layout()
        plt.savefig('training_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Mostrar m√©tricas finales
        precision_final = historial.history['val_accuracy'][-1]
        perdida_final = historial.history['val_loss'][-1]
        print(f"üìä Precisi√≥n final en validaci√≥n: {precision_final:.4f}")
        print(f"üìä P√©rdida final en validaci√≥n: {perdida_final:.4f}")
    
    def evaluar_modelo(self, modelo, gen_validacion):
        """Eval√∫a el modelo en el conjunto de validaci√≥n"""
        print("üî¨ Evaluando modelo en conjunto de validaci√≥n...")
        
        # Resetear generador
        gen_validacion.reset()
        
        # Predicciones
        predicciones = modelo.predict(gen_validacion, verbose=1)
        clases_predichas = np.argmax(predicciones, axis=1)
        
        # Etiquetas verdaderas
        clases_verdaderas = gen_validacion.classes
        etiquetas_clases = list(gen_validacion.class_indices.keys())
        
        # Reporte de clasificaci√≥n
        print("\nüìã Reporte de Clasificaci√≥n:")
        print("=" * 80)
        reporte = classification_report(clases_verdaderas, clases_predichas, 
                                     target_names=etiquetas_clases, 
                                     output_dict=True)
        
        # Mostrar m√©tricas por clase
        for nombre_clase, metricas in reporte.items():
            if isinstance(metricas, dict) and nombre_clase not in ['accuracy', 'macro avg', 'weighted avg']:
                nombre_espa√±ol = self.informacion_clases.get(nombre_clase, {}).get('nombre', nombre_clase)
                print(f"{nombre_espa√±ol:30} | Precisi√≥n: {metricas['precision']:.3f} | "
                      f"Recall: {metricas['recall']:.3f} | F1: {metricas['f1-score']:.3f}")
        
        print("=" * 80)
        print(f"Precisi√≥n general: {reporte['accuracy']:.4f}")
        print(f"F1-score promedio: {reporte['weighted avg']['f1-score']:.4f}")

def principal():
    """Funci√≥n principal para entrenar el modelo"""
    print("üëÅÔ∏è ENTRENADOR DE CLASIFICADOR DE ENFERMEDADES OCULARES")
    print("=" * 60)
    
    # Configuraci√≥n
    RUTA_DATASET = "./Dataset"  # Cambia esta ruta si es necesario
    EPOCAS = 25
    NOMBRE_MODELO = "eye_disease_model.h5"
    
    # Verificar que existe el dataset
    if not os.path.exists(RUTA_DATASET):
        print(f"‚ùå Error: No se encontr√≥ el dataset en {RUTA_DATASET}")
        print("üìÅ Aseg√∫rate de que la carpeta Dataset est√© en el directorio actual")
        return
    
    # Crear entrenador
    entrenador = EntrenadorEnfermedadesOculares()
    
    # Entrenar modelo
    try:
        modelo, historial = entrenador.entrenar_modelo(
            ruta_dataset=RUTA_DATASET,
            epocas=EPOCAS,
            ruta_guardado=NOMBRE_MODELO
        )
        
        print("\nüéâ ¬°ENTRENAMIENTO COMPLETADO EXITOSAMENTE!")
        print("=" * 60)
        print(f"‚úÖ Modelo guardado: {NOMBRE_MODELO}")
        print(f"‚úÖ √çndices de clases: class_indices.npy")
        print(f"‚úÖ Gr√°ficos: training_results.png")
        print("\nüöÄ Ahora puedes ejecutar 'streamlit run app.py' para usar la aplicaci√≥n")
        
    except Exception as e:
        print(f"\n‚ùå Error durante el entrenamiento: {str(e)}")
        print("üîß Verifica que todas las dependencias est√°n instaladas correctamente")

if __name__ == "__main__":
    principal()